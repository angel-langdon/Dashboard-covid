{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se ha encontrado el día 01-06-2021\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "import time\n",
    "\n",
    "\n",
    "DATA_FOLDER = \"./data\"\n",
    "base_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "date_format ='%m-%d-%Y' #01-22-2020.csv\n",
    "df_date_format = '%Y-%m-%d'\n",
    "communites_list = ['Castilla-Leon',\n",
    " 'Cataluña',\n",
    " 'Ceuta',\n",
    " 'Murcia',\n",
    " 'La Rioja',\n",
    " 'Baleares',\n",
    " 'Canarias',\n",
    " 'Cantabria',\n",
    " 'Andalucia',\n",
    " 'Asturias',\n",
    " 'Valencia',\n",
    " 'Melilla',\n",
    " 'Navarra',\n",
    " 'Galicia',\n",
    " 'Aragon',\n",
    " 'Madrid',\n",
    " 'Extremadura',\n",
    " 'Castilla-La Mancha',\n",
    " 'Pais Vasco']\n",
    "\n",
    "\n",
    "#communites_geojson = read_communites_geojson()\n",
    "\n",
    "correspondence_dict = {'Andalusia': 'Andalucia',\n",
    " 'Aragon': 'Aragon',\n",
    " 'Asturias': 'Asturias',\n",
    " 'Baleares': 'Baleares',\n",
    " 'C. Valenciana': 'Valencia',\n",
    " 'Canarias': 'Canarias',\n",
    " 'Cantabria': 'Cantabria',\n",
    " 'Castilla - La Mancha': 'Castilla-La Mancha',\n",
    " 'Castilla y Leon': 'Castilla-Leon',\n",
    " 'Catalonia': 'Cataluña',\n",
    " 'Ceuta': 'Ceuta',\n",
    " 'Extremadura': 'Extremadura',\n",
    " 'Galicia': 'Galicia',\n",
    " 'La Rioja': 'La Rioja',\n",
    " 'Madrid': 'Madrid',\n",
    " 'Melilla': 'Melilla',\n",
    " 'Murcia': 'Murcia',\n",
    " 'Navarra': 'Navarra',\n",
    " 'Pais Vasco': 'Pais Vasco'}\n",
    "\n",
    "#communities_geojson = read_communites_geojson(\"spain-communites-v2\")\n",
    "\n",
    "def correspondence_string(string, list_to_match):\n",
    "    current_ratio = 0\n",
    "    return_string = None\n",
    "    for string_from_list in list_to_match:\n",
    "        ratio = SequenceMatcher(None, string, string_from_list).ratio()\n",
    "        if ratio > current_ratio:\n",
    "            current_ratio = ratio\n",
    "            return_string = string_from_list\n",
    "    return return_string\n",
    "\n",
    "def get_correspondence_dict(covid_communities_name, string_list = communites_list):\n",
    "    dic_correspondence = {}\n",
    "    for original_string in covid_communities_name:\n",
    "        dic_correspondence[original_string] = correspondence_string(original_string, string_list)\n",
    "    return dic_correspondence\n",
    "\n",
    "#get_correspondence_dict(dfs[0][\"Province_State\"])\n",
    "\n",
    "\n",
    "def format_day(day_str):\n",
    "    day = datetime.strptime(day_str, \"%m-%d-%Y\")\n",
    "    return datetime.strftime(day, \"%Y-%m-%d\")\n",
    "\n",
    "def read_communites_geojson(name = \"spain-communities\" ):\n",
    "    with open(f\"./data/geojson/{name}.geojson\") as f:\n",
    "        geojson = json.load(f)\n",
    "        communites = []\n",
    "        for region in geojson['features']:\n",
    "            nameunit = region[\"properties\"][\"nameunit\"]\n",
    "            if \"/\" in nameunit:\n",
    "                region[\"properties\"][\"nameunit\"] = nameunit.split(\"/\")[0]\n",
    "            if 'Ciudad Autónoma de Ceuta' in nameunit:\n",
    "                region[\"properties\"][\"nameunit\"] = \"Ceuta\"\n",
    "            elif 'Ciudad Autónoma de Melilla' in nameunit:\n",
    "                region[\"properties\"][\"nameunit\"] = \"Melilla\"\n",
    "            elif 'Comunidad Foral de Navarra' in nameunit:\n",
    "                region[\"properties\"][\"nameunit\"] = \"Navarra\"\n",
    "            communites.append(region[\"properties\"][\"nameunit\"])\n",
    "    return geojson, communites\n",
    "\n",
    "def get_communites(geojson):\n",
    "    regions = []\n",
    "    for region in geojson['features']:\n",
    "        if region[\"properties\"][\"name\"] == \"Valencia\":\n",
    "            region[\"properties\"][\"name\"] = \"C. Valenciana\"\n",
    "        regions.append(region[\"properties\"][\"name\"])\n",
    "    return regions\n",
    "        \n",
    "\n",
    "def generate_days(start_date):\n",
    "    end_date = datetime.now()\n",
    "    step = timedelta(days=1)\n",
    "    result = []\n",
    "    while start_date < end_date:\n",
    "        result.append(start_date.strftime(date_format))\n",
    "        start_date += step\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#download_all_datasets()\n",
    "        \n",
    "def add_to_list(l, lat_sum, lon_sum):\n",
    "    # For moving Canary Islands near Spain.\n",
    "    # l is the list of list of lists .... of coordinates\n",
    "    if isinstance(l, list) and isinstance(l[0], float) and isinstance(l[1], float):\n",
    "        return l[0] + lat_sum, l[1] + lon_sum \n",
    "    return [add_to_list(sub, lat_sum, lon_sum) for sub in l]\n",
    "\n",
    "def reduce_precission(l, ndigits):\n",
    "    if not isinstance(l, list):\n",
    "        return round(l, ndigits)\n",
    "    return [reduce_precission(sub, ndigits) for sub in l]\n",
    "\n",
    "\n",
    "def read_original_to_displaced_canaries():\n",
    "    lat_sum = 6.65456\n",
    "    lon_sum = 5.65412\n",
    "    geojson,b = read_communites_geojson_v1('spain-communities')\n",
    "    for region in geojson['features']:\n",
    "        name = region[\"properties\"][\"name\"]\n",
    "        if name == \"Canarias\":\n",
    "            region[\"geometry\"][\"coordinates\"] = add_to_list(region[\"geometry\"][\"coordinates\"],\n",
    "                                                           lat_sum,\n",
    "                                                           lon_sum)\n",
    "    with open(f\"./data/geojson/spain-communites-displaced-canary.geojson\", \"w\") as f:\n",
    "        json.dump(geojson, f)\n",
    "\n",
    "\n",
    "def read_communites_geojson_v1(name = \"spain-communities\" ):\n",
    "    with open(f\"./data/geojson/{name}.geojson\") as f:\n",
    "        geojson = json.load(f)\n",
    "        communites = []\n",
    "    for region in geojson['features']:\n",
    "        name = region[\"properties\"][\"name\"]\n",
    "        communites.append(name)\n",
    "            \n",
    "    return geojson, communites\n",
    "#communities_geojson,b = read_communites_geojson_v1()\n",
    "\n",
    "\n",
    "        \n",
    "def read_population_dataset(name = 'spain-communities-2020.csv'):\n",
    "    \n",
    "    def clean_name_pop(name):\n",
    "        if \" \" in name:\n",
    "            name = \" \".join(name.split(\" \")[1:])\n",
    "        if \",\" in name:\n",
    "            split = name.split(\",\")\n",
    "            name = \" \".join(split[1:] + [split[0]])\n",
    "        return name\n",
    "\n",
    "    def clean_pop_pop(pop):\n",
    "        if \".\" in pop:\n",
    "            return int(pop.replace(\".\",\"\"))\n",
    "    population = pd.read_csv(f\"./data/population/{name}\", sep=\";\")\n",
    "    #population = population[population[\"Periodo\"] == 2019]\n",
    "    #population = population[population[\"Sexo\"] == \"Total\"] \n",
    "    population.drop(columns=['Periodo', 'Sexo'], inplace=True)\n",
    "    population['Comunidades y Ciudades Autónomas'] = [clean_name_pop(name) for name in population['Comunidades y Ciudades Autónomas'] ]\n",
    "    population[\"Total\"] = [clean_pop_pop(pop) for pop in population[\"Total\"]]\n",
    "    population.loc[population['Comunidades y Ciudades Autónomas'] == \"Comunitat Valenciana\", 'Comunidades y Ciudades Autónomas'] = 'Valencia'\n",
    "    population.loc[population['Comunidades y Ciudades Autónomas'] == \"Comunidad Foral de Navarra\", 'Comunidades y Ciudades Autónomas'] = 'Navarra'\n",
    "    correspondence_dict_population = get_correspondence_dict(df_diario_acumulado[\"Comunidad Autónoma\"].unique(),population['Comunidades y Ciudades Autónomas'])\n",
    "    population.rename(columns = {'Comunidades y Ciudades Autónomas': 'Comunidad'}, inplace = True)\n",
    "    return population, correspondence_dict_population\n",
    "\n",
    "def get_pop(com):\n",
    "    com = correspondence_dict_population[com]\n",
    "    return int(pop_df.loc[pop_df[\"Comunidad\"]==com, 'Total'])\n",
    "\n",
    "def tasa_mortalidad_y_letalidad(df):\n",
    "    df[\"% de letalidad\"] = df['Muertes'] * 100 / df['Confirmados'] \n",
    "    df[\"% Población contagiada total\"] = df['Confirmados'] * 100 / df[\"Población\"]\n",
    "    df[\"% Población fallecida total\"] = df['Muertes'] * 100 / df[\"Población\"]\n",
    "    \n",
    "    \n",
    "def obtener_df_semanal(df):\n",
    "    df[\"Datetime\"] = pd.to_datetime(df['Día'], format=df_date_format)\n",
    "    df[\"dia_sem\"] = [day.weekday() for day in df['Datetime']]\n",
    "    df_semanal = df[df[\"dia_sem\"] == 6].copy()\n",
    "    df.drop(columns= [\"dia_sem\", 'Datetime'], inplace = True)\n",
    "    df_semanal.drop(columns = [\"dia_sem\", 'Datetime'], inplace = True)\n",
    "    return df_semanal\n",
    "\n",
    "def save_df(name, df):\n",
    "    df.to_csv(os.path.join(DATA_FOLDER, \"final_data\", name),\n",
    "                encoding='UTF-8',\n",
    "              sep=\";\", index= False)\n",
    "    \n",
    "def obtener_df_semanal_desacumulado(df):\n",
    "    dfs_desacumulados = []\n",
    "    for com in df[\"Comunidad Autónoma\"].unique():\n",
    "        df_com =  df[df['Comunidad Autónoma']==com].copy()\n",
    "        for column in [\"Confirmados\", \"Muertes\"]:\n",
    "            df_com.sort_values(by=\"Día\", inplace = True)\n",
    "            df_com[column] = df_com[column].diff()\n",
    "        df_com.dropna(inplace = True)\n",
    "        dfs_desacumulados.append(df_com)\n",
    "        \n",
    "    dfs_desacumulado = pd.concat(dfs_desacumulados)\n",
    "    dfs_desacumulado.drop(['Población',r'% de letalidad',\n",
    "                    r'% Población contagiada total',\n",
    "                          r'% Población fallecida total'],\n",
    "                         inplace = True,\n",
    "                         axis = 1)\n",
    "    dfs_desacumulado.sort_values(by = \"Día\", inplace = True)\n",
    "    return dfs_desacumulado\n",
    "\n",
    "\n",
    "def correct_names():\n",
    "    def read_population_dataset_custom(name = 'spain-communities-2020.csv'):\n",
    "        def clean_name_pop(name):\n",
    "            if \" \" in name:\n",
    "                name = \" \".join(name.split(\" \")[1:])\n",
    "            if \",\" in name:\n",
    "                split = name.split(\",\")\n",
    "                name = \" \".join(split[1:] + [split[0]])\n",
    "            return name\n",
    "        def clean_pop_pop(pop):\n",
    "            if \".\" in pop:\n",
    "                return int(pop.replace(\".\",\"\"))\n",
    "        population = pd.read_csv(f\"./data/population/{name}\", sep=\";\")\n",
    "        population.drop(columns=['Periodo', 'Sexo'], inplace=True)\n",
    "        population['Comunidades y Ciudades Autónomas'] = [clean_name_pop(name) for name in population['Comunidades y Ciudades Autónomas'] ]\n",
    "        population[\"Total\"] = [clean_pop_pop(pop) for pop in population[\"Total\"]]\n",
    "        return population\n",
    "\n",
    "\n",
    "    corres_dict = get_correspondence_dict(dfs[0]['Province_State'], read_population_dataset_custom()['Comunidades y Ciudades Autónomas'])\n",
    "    corres_dict['Valencia'] = 'Comunitat Valenciana'\n",
    "    corres_dict['Navarra'] = 'Comunidad Foral de Navarra'\n",
    "    corres_dict['Total'] = 'Total'\n",
    "    \n",
    "    for key,value in corres_dict.items():\n",
    "        if \" \" == value[0]:\n",
    "            corres_dict[key]=value[1:]\n",
    "    return corres_dict\n",
    "\n",
    "\n",
    "def download_all_datasets():\n",
    "    start_date = datetime(month = 5, day = 14, year=2020)    \n",
    "    days = generate_days(start_date)\n",
    "    descargados = os.listdir(os.path.join(DATA_FOLDER,\n",
    "                                         \"covid_data\"))\n",
    "    for i, day in enumerate(days):\n",
    "        filename = f\"{day}.csv\"\n",
    "        if filename not in descargados:\n",
    "            try:\n",
    "                df = pd.read_csv(base_url + filename)\n",
    "                #df = df.loc[df['Country_Region'] == \"Spain\"]\n",
    "                df.to_csv(f\"{DATA_FOLDER}/covid_data/{filename}\", index = False)\n",
    "            except:\n",
    "                print(f\"No se ha encontrado el día {day}\")\n",
    "\n",
    "download_all_datasets()\n",
    "    \n",
    "dfs = []\n",
    "\n",
    "for file in sorted(os.listdir(os.path.join(DATA_FOLDER, \"covid_data\"))):\n",
    "    if \".csv\" in file:\n",
    "        day = file[:-4]\n",
    "        df = pd.read_csv(f\"{DATA_FOLDER}/covid_data/{file}\")\n",
    "        df = df.loc[(df['Country_Region'] == \"Spain\") & (df['Province_State'] != \"Unknown\")]\n",
    "        df[\"Province_State\"] = [correspondence_dict[province] for province in df[\"Province_State\"]]\n",
    "        df = df[['Province_State','Country_Region',\n",
    "                'Last_Update','Confirmed', \n",
    "                'Deaths', 'Recovered',\n",
    "                'Active']]\n",
    "        df[\"Day\"] = [format_day(day) for i in range(len(df))]\n",
    "        df.drop(columns = [\"Active\", 'Recovered', 'Last_Update'], inplace = True)\n",
    "            \n",
    "        # df.to_csv(\"data.csv\", index = False)\n",
    "        dfs.append(df)\n",
    "\n",
    "df_diario_acumulado = pd.concat(dfs)\n",
    "df_diario_acumulado.drop(columns=[\"Country_Region\"], inplace = True)\n",
    "df_diario_acumulado.rename(columns={\"Province_State\": \"Comunidad Autónoma\",\n",
    "                   \"Confirmed\": \"Confirmados\",\n",
    "                  \"Deaths\": \"Muertes\",\n",
    "                   \"Day\":\"Día\"}, inplace = True)\n",
    "pop_df, correspondence_dict_population = read_population_dataset()\n",
    "df_diario_acumulado['Población'] = df_diario_acumulado[\"Comunidad Autónoma\"].apply(lambda x: get_pop(x))\n",
    "del pop_df, correspondence_dict_population\n",
    "correct_communites = correct_names()\n",
    "\n",
    "\n",
    "def get_total_rows(df_diario_acumulado):\n",
    "    dfs=[]\n",
    "    for day in df_diario_acumulado[\"Día\"].unique():\n",
    "        df = df_diario_acumulado.loc[df_diario_acumulado['Día'] == day].copy()\n",
    "        total_row = {'Comunidad Autónoma':'Total', 'Confirmados':sum(df['Confirmados']),\n",
    "                    'Muertes': sum(df['Muertes']), 'Día':day, 'Población':sum(df['Población'])}\n",
    "        df = df.append(total_row, ignore_index = True)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    return df.sort_values(by='Día')\n",
    "\n",
    "df_diario_acumulado = get_total_rows(df_diario_acumulado)\n",
    "\n",
    "tasa_mortalidad_y_letalidad(df_diario_acumulado)\n",
    "\n",
    "df_diario_acumulado['Comunidad/Ciudad Autónoma'] = [correct_communites[com] for com in df_diario_acumulado['Comunidad Autónoma']]\n",
    "df_semanal_acumulado = obtener_df_semanal(df_diario_acumulado)\n",
    "df_semanal_desacumulado = obtener_df_semanal_desacumulado(df_semanal_acumulado)\n",
    "\n",
    "save_df('diario_acumulado.csv', df_diario_acumulado)\n",
    "save_df('semanal_acumulado.csv', df_semanal_acumulado)\n",
    "save_df('semanal_desacumulado.csv', df_semanal_desacumulado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
